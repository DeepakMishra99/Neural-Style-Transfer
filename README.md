 <h1 id="neural-style-transfer">Neural Style Transfer</h1>
    <h2 id="overview">Overview</h2>
    <p><em>Neural Style Transfer</em> is a technique that uses deep learning to blend the <em>content</em> of one image with the <em>artistic style</em> of another image. This process allows you to apply the visual style of famous artworks to your own photos or create unique artistic renditions.</p>
    <h2 id="how-it-works">How it Works</h2>
    <ol>
    <li><strong>Content and Style Images:</strong> The algorithm takes two images as input:</li>
    <ul>
    <li><strong>Content Image:</strong> The image whose content you want to preserve.</li>
    <li><strong>Style Image:</strong> The image whose artistic style you want to transfer.</li>
    </ul>
    <li><strong>Deep Convolutional Neural Networks (CNNs):</strong> Pre-trained CNNs (like VGG) are used to extract <em>feature representations</em> from both images.</li>
    <li><strong>Feature Extraction:</strong></li>
    <ul>
    <li><strong>Content Representation:</strong> Higher-level layers of the CNN capture the <em>content</em> of the image.</li>
    <li><strong>Style Representation:</strong> <em>Gram matrices</em>, calculated from the feature maps of lower-level layers, represent the <em>style</em> of the image.</li>
    </ul>
    <li><strong>Optimization:</strong> The algorithm generates a new image by iteratively modifying its pixel values to:</li>
    <ul>
    <li>Match the <em>content representation</em> of the content image.</li>
    <li>Match the <em>style representation</em> of the style image.</li>
    </ul>
    <li><strong>Loss Functions:</strong></li>
    <ul>
    <li><strong>Content Loss:</strong> Measures how much the generated image retains the <em>content</em> of the content image.</li>
    <li><strong>Style Loss:</strong> Measures how well the generated image matches the <em>style</em> of the style image.</li>
    <li><strong>Total Loss:</strong> A weighted combination of the <em>content loss</em> and <em>style loss</em>, which the algorithm minimizes during the optimization process.</li>
    </ul>
    </ol>

<h2>ğŸš€ How to Run the Project</h2>

<ol>
  <li>ğŸ´ <strong>Fork</strong> the repository</li>
  <li>ğŸ“¦ <strong>Install required libraries</strong><br>
      ğŸ› ï¸ Run Command: <code>pip install -r requirements.txt</code>
  </li>
  <li>ğŸ§  <strong>Run Streamlit App</strong><br>
      ğŸ’» Command: <code>streamlit run app.py</code>
  </li>
  <li>ğŸ–¼ï¸ <strong>Upload</strong> the <code>Content</code> and <code>Style</code> Images</li>
  <li>â³ <strong>Wait for 4 minutes</strong></li>
  <li>ğŸ¨ <strong>Output Image</strong> will show the final result</li>
</ol>

<h2>ğŸ—‚ï¸ Project Structure</h2>

<ul>
  <li><strong>ğŸ“ Images</strong> â€“ Folder containing project images
    <ul>
      <li>ğŸ–¼ï¸ <code>content.jpg</code> â€“ Content Image</li>
      <li>ğŸ–Œï¸ <code>style.jpg</code> â€“ Style Image</li>
    </ul>
  </li>
  <li><strong>ğŸ““ Notebook</strong>
    <ul>
      <li>ğŸ“˜ <code>neural-style-transfer-with-tensorflow.ipynb</code> â€“ Jupyter Notebook</li>
    </ul>
  </li>
  <li>ğŸŒ <strong>venv</strong> â€“ Virtual Environment</li>
  <li>ğŸ“„ <strong>app.py</strong> â€“ Main module to run the project</li>
  <li>ğŸ“‰ <strong>losses.py</strong> â€“ Functions to evaluate losses</li>
  <li>ğŸ§© <strong>model.py</strong> â€“ VGG19 model configuration</li>
  <li>ğŸ§¼ <strong>preprocessing.py</strong> â€“ Preprocesses both images</li>
  <li>ğŸ” <strong>style_transfer.py</strong> â€“ All-in-one module for processing, modeling, evaluating, and outputting the stylized image</li>
  <li>ğŸ§¾ <strong>requirements.txt</strong> â€“ Dependency file<br>
      ğŸ› ï¸ Run: <code>pip install -r requirements.txt</code>
  </li>
  <li>ğŸš« <strong>.gitignore</strong> â€“ Files and folders to ignore in GitHub</li>
  <li>ğŸ“˜ <strong>README.md</strong> â€“ This documentation file</li>
</ul>